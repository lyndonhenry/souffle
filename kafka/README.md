# README

Welcome to Souffle on Kafka.

## Experiments

The experiments are managed by four bash scripts.

The scripts do not depend on each other, and no other script depends on them -- they are merely helper scripts.

The scripts are:

1. `script-to-run-in-docker.sh` 
2. `script-to-generate-datasets.sh` 
3. `script-to-generate-experiments.sh`
4. `script-to-run-experiments.sh`

Each script is to be run from the Souffle root directory, i.e. `./kafka/my-script.sh` and not `cd kafka && ./my-script.sh`.

The scripts correspond to each of the steps involved in running the experiments, and are presented in order.

The purpose of each script is as follows:

- `script-to-run-in-docker.sh`
    - Pulls and runs the Docker image for Souffle on Kafka.
    - The script shows which parameters to pass `docker run`, to mount directories.
    - All other scripts should be run from within the Docker container that this script pulls and runs.
    
- `script-to-generate-datasets.sh`
    - Downloads all datasets for the experiments, formats them, and places them in the S3 bucket.

- `script-to-generate-experiments.sh`
    - Generates all `docker-compose.yml` files for the experiments.
    - Each Docker compose file is placed in a directory that uniquely identifies the experiment it runs.
    - These are placed a subdirectory of `s3://souffle-on-kafka/docker-compose/`.
    - This subdirectory is either `example`, `yes-cloud`, or `no-cloud`.
    - The `example` docker compose files are used to test the system.
    - The `yes-cloud` docker compose files **are to be run in Azure**.
    - The `no-cloud` docker compose files **are to be run on plang8**.
    - Note that the user will be prompted to continue generating the real experiments once the example experiments are generated.
    - By terminating the script before the real experiments are generated, the system can be tested on the examples only.
    
- `script-to-run-experiments.sh`
    - Runs the experiments, using Docker compose commands.
    - A user's AWS credentials are written to a `.env` file; the script then changes to the directory of the `.env` file, so that calls to `docker-compose` use the contents of this file to populate the environment variables.
    - Each experiment generates a log file in `s3://souffle-on-kafka/output/log`; we check for the existence of this log file in the S3 bucket to signal an experiment's termination.
    

## Results

Results are obtained from a log file generated by an experiment.

The log file is generated to the S3 bucket at the conclusion of an experiment.

The path of the log file is `s3://souffle-on-kafka/output/log/<experiment-name>.log`, where `<experiment-name>` is the unique name of the experiment. 

In particular, the experiment name will be the same as the directory containing the `docker-compose.yml` file that defines the experiment, in the S3 bucket at `s3://souffle-on-kafka/docker-compose/`.

The schema of log messages is described by the following grammar.

~~~
LOG_MESSAGE := HEAD,BODY
HEAD := <stratum-name>,<message-index>,<timestamp-mode>,<timestamp>
BODY := beginBashScript
    | endBashScript
    | beginSouffleProgram
    | endSouffleProgram
    | downloadInput,<data-size>,<line-count>
    | uploadOutput,<data-size>,<line-count>
    | printMetadata,<benchmark-program>,<data-type>,<split-size>,<join-type>,<kafka-mode>,<evaluation-algorithm>,<dataset-name>,<thread-count>,<unique-id>
    | beginClient
    | endClient
    | beginProduction,<topic-name>
    | endProduction,<topic-name>
    | beginConsumption,<topic-name>
    | endConsumption,<topic-name>
    | beginProduce,<topic-name>,<payload-size>,<payload-type-size>
    | endProduce,<topic-name>
    | beginConsume,<topic-name>
    | endConsume,<topic-name>,<payload-size>,<payload-type-size>
    | beginPollProducer
    | endPollProducer
    | beginPollConsumer
    | endPollConsumer
~~~

A log message is composed of a `HEAD` and a `BODY`.

The `HEAD` of a log message consists of each of the following fields.

- `<stratum-name>` is the name of the stratum emitting this message, or "main". Note that the -2 stratum is responsible for reading and producing input files, while the -3 stratum does the same for output files.
- `<message-index>` is the index or count of the current message.
- `<timestamp>` is the timestamp in milliseconds since the last message.

The `BODY` of a log message contains information about the operation which cased the message to be emitted.

The `BODY` of a log message starts with the name of the operation to which the message corresponds, followed by a number of values involved in that operation.

The following message bodies are emitted by operations from the bash script that is responsible for managing execution of the Souffle program.

- `printMetadata,<benchmark-program>,<data-type>,<split-size>,<join-type>,<kafka-mode>,<evaluation-algorithm>,<dataset-name>,<thread-count>,<unique-id>`
    - Emmitted immediately after the bash script managing the Souffle program execution begins. This effectively gives the input parameters of the experiment.
    - `<benchmark-program>` is the name of the benchmark program in use.
    - `<data-type>` is the Souffle data type, either `number` or `symbol`.
    - `<split-size>` is the number of splits in the Souffle program for the IDB relation.
    - `<join-type>` is the type of join used for the splits in the Souffle program.
    - `<kafka-mode>` is the Kafka mode, either `no-kafka` for no use of Kafka, `one-kafka` for running each Souffle program strata as a separate process in the same Docker container, or `many-kafka` for running each Souffle program strata in a separate Docker container.
    - `<evaluation-algorithm>` is the evaluation algorithm used, either `SNE`, `GSNE`, `GPSNE`, or `GPCSNE`.
    - `<dataset-name>` is the name of the dataset used in the experiment.
    - `<thread-count>` is the number of threads used by the Souffle program.
    - `<unique-id>` is the unique identifier of this experiment.
- `beginBashScript`
    - Emmitted immediately after the `printMetadata` message is emitted.
- `endBashScript`
    - Emitted immediately before the bash script managing the Souffle program execution ends.
- `beginSouffleProgram`
    - Emitted immediately before execution of the Souffle program.
- `endSouffleProgram`
    - Emitted immediately after the execution of the Souffle program.
- `downloadInput,<data-size>,<line-count>`
    - Emitted immediately after the input for the Souffle program has been downloaded.
    - `<data-size>` is the size in bytes of the downloaded file (or files).
    - `<line-count>` is the number of lines in the downloaded file (or files).
- `uploadOutput,<data-size>,<line-count>`
    - Emitted immediately after the output for the Souffle program has been uploaded.
    - `<data-size>` is the size in bytes of the uploaded file (or files).
    - `<line-count>` is the number of lines in the uploaded file (or files).

The following message bodies are mmitted by operations from within the execution of the Souffle program itself.

- `beginClient`
    - Emitted immediately after the Souffle program's client is connected to Kafka.
- `endClient`
    - Emitted immediately before the Souffle program's client terminates its connection, along with the program itself.
- `beginProduction,<topic-name>`
    - Emitted immediately after instantiation of a producer for a given topic.
    - `<topic-name>` is the name of the topic on which to produce.
- `endProduction,<topic-name>`
    - Emmitted immediately after terminating all production on a given topic.
    - `<topic-name>` is the name of the topic.
- `beginConsumption,<topic-name>`
    - Emitted immediately after instantiation of a consumer for a given topic.
    - `<topic-name>` is the name of the topic on which to consume.
- `endConsumption,<topic-name>`
    - Emmitted immediately after terminating all consumption on a given topic.
    - `<topic-name>` is the name of the topic.
- `beginProduce,<topic-name>,<payload-size>,<payload-type-size>`
    - Emitted before production of a message on given topic.
    - `<topic-name>` The name of the topic.
    - `<payload-size>` Number of elements in the payload vector.
    - `<payload-type-size>` Size in bytes of each element in the payload vector.
- `endProduce,<topic-name>`
    - Emitted after production of a message on a given topic. 
    - `<topic-name>` is the name of the topic.
- `beginConsume,<topic-name>`
    - Emitted before consumption of a message on a given topic. 
    - `<topic-name>` is the name of the topic.
- `endConsume,<topic-name>,<payload-size>,<payload-type-size>`
    - Emitted after consumption of a message on given topic.
    - `<topic-name>` is the name of the topic.
    - `<payload-size>` is the number of elements in the payload vector.
    - `<payload-type-size>` is the size in bytes of each element in the payload vector.
- `beginPollProducer`
    - Emitted after polling of producer to process outbound messages has begun.
- `endPollProducer`
    - Emitted after polling of producer to process outbound messages has ended.
- `beginPollConsumer`
    - Emitted after polling of consumer to process inbound messages has begun.
- `endPollConsumer`
    - Emitted after polling of consumer to process inbound messages has ended.

